import Link from "next/link";
import { TelcoOpsDocsLayout } from "@/components/TelcoOpsDocsLayout";

export const metadata = {
  title: "Correlation and RCA Logic | TelcoOps",
  description: "Deep dive into alert correlation rules and RCA generation flow.",
};

export default function TelcoOpsCorrelationRcaPage() {
  return (
    <TelcoOpsDocsLayout>
      <article className="prose prose-slate max-w-none dark:prose-invert">
        <h1>Correlation and RCA Logic</h1>

        <p className="lead">
          TelcoOps correlates alerts using deterministic rules to ensure transparent incident creation. RCA is then generated by a
          baseline rule set and optionally augmented with LLM reasoning.
        </p>

        <h2>Correlation Algorithm</h2>

        <p>The correlator uses three simple but effective rules:</p>

        <ol>
          <li><strong>Tag grouping</strong>: Alerts are grouped by <code>tags.incident</code>.</li>
          <li><strong>Threshold gating</strong>: Only groups with at least 10 alerts become incidents.</li>
          <li><strong>Window constraint</strong>: Alerts must fall within a 15 minute window.</li>
        </ol>

        <h3>Why this works for the MVP</h3>

        <ul>
          <li>Gives a deterministic incident count for a demo scenario.</li>
          <li>Avoids ML-based clustering complexity.</li>
          <li>Eliminates stale incidents by correlating only the latest alert batch.</li>
        </ul>

        <h2>Baseline RCA</h2>

        <p>
          The baseline RCA is intentionally simple: a known root cause hypothesis with a confidence score. It provides a stable
          comparator for LLM output and ensures RCA is always available even if the LLM fails.
        </p>

        <h2>LLM RCA</h2>

        <p>
          LLM RCA builds a structured prompt with a fixed JSON schema, the incident payload, a sample of alerts, and RAG context. The
          response must parse into JSON; otherwise the API returns a 502 error.
        </p>

        <h3>Prompt Contract</h3>

        <ul>
          <li>Return only JSON without code fences.</li>
          <li>Include hypotheses, confidence scores, evidence, and model metadata.</li>
          <li>Do not invent remediation commands.</li>
        </ul>

        <h2>RCA Output Storage</h2>

        <p>
          Both baseline and LLM RCA outputs are stored in the same <code>rca_artifacts</code> table. LLM results additionally store the
          prompt and response payloads for auditability.
        </p>

        <h2>Design Tradeoffs</h2>

        <ul>
          <li><strong>Rule-based correlation</strong>: Clear and explainable, but not adaptive to new incident patterns.</li>
          <li><strong>Baseline RCA simplicity</strong>: Limited coverage, but stabilizes trust in the system.</li>
          <li><strong>LLM JSON contract</strong>: Forces structure, but still subject to occasional parse failures.</li>
        </ul>

        <hr />

        <p className="text-sm text-muted-foreground">
          Next: <Link href="/docs/telcoops/deep-dives/llm-rag-pipeline" className="text-primary hover:underline">LLM and RAG pipeline</Link>
        </p>
      </article>
    </TelcoOpsDocsLayout>
  );
}
